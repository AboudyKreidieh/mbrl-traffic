{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macroscopic Modeling of Multi-Lane Traffic Flow Dynamics\n",
    "\n",
    "TODO\n",
    "\n",
    "## Table of Content\n",
    "\n",
    "1. [Data Cleaning](#1.-Data-Cleaning)\n",
    "2. [Plotting Microscopic Data](#2.-Plotting-Microscopic-Data) <br />\n",
    "   2.1 [Ring Road](#2.1-Ring-Road) <br />\n",
    "   2.2 [Highway](#2.2-Highway)\n",
    "3. [Plotting Macroscopic Data](#3.-Plotting-Macroscopic-Data) <br />\n",
    "   3.1 [Ring Road](#3.1-Ring-Road) <br />\n",
    "   3.2 [Highway](#3.2-Highway)\n",
    "4. [Time-Frequency Analysis of Macroscopic Data](#4.-Time-Frequency-Analysis-of-Macroscopic-Data) <br />\n",
    "   4.1 [Ring Road](#4.1-Ring-Road) <br />\n",
    "   4.2 [Highway](#4.2-Highway)\n",
    "5. [Modeling Results](#5.-Modeling-Results) <br />\n",
    "   5.1 [Lighthill-Whitham-Richards (LWR) Model](#5.1-Lighthill-Whitham-Richards-(LWR)-Model) <br />\n",
    "   5.2 [Aw-Rascle-Zhang (ARZ) Model](#5.2-Aw-Rascle-Zhang-(ARZ)-Model) <br />\n",
    "   5.3 [Linearized ARZ Model](#5.3-Linearized-ARZ-Model) <br />\n",
    "   5.4 [Non-Local Model](#5.4-Non-Local-Model) <br />\n",
    "   5.5 [Fully-Connected Neural Network](#5.5-Fully-Connected-Neural-Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning\n",
    "\n",
    "We begin by performing some data cleaning. Sumo simulations within Flow generate emission csv files with several datapoints. For our purposes, we only care about the following:\n",
    "\n",
    "* time: the timestamp of the given sample\n",
    "* id: the name of the vehicle associated with this sample\n",
    "* relative_position: the position of the vehicle on a given edge\n",
    "* speed: the speed of the vehicle\n",
    "* edge_id: the edge the vehicle is current residing on\n",
    "* lane_number: the lane index of the vehicle, starting from 0 on the rightmost lane\n",
    "\n",
    "Therefore, in order to reduce the size of the generate files, the below script trims out any unnecesary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the network type.\n",
    "RING    = True\n",
    "MERGE   = False\n",
    "HIGHWAY = False\n",
    "\n",
    "# Specify the directories containing the files you'd like to clean.\n",
    "directory = [\"data/ring-1-lane/baseline/sumo-idm/50\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/55\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/60\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/65\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/70\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/75\"]\n",
    "\n",
    "\n",
    "for directory_i in directory:\n",
    "    # get the names of all files in the directory\n",
    "    files = os.listdir(directory_i)\n",
    "    files.remove(\"micro\")\n",
    "    files.remove(\"macro\")\n",
    "\n",
    "    for i, fp in enumerate(sorted(files)):\n",
    "        # import the next file\n",
    "        df = pd.read_csv(os.path.join(directory_i, fp))\n",
    "\n",
    "        # keep only the datapoints we care about\n",
    "        df = df[[\"time\", \"id\", \"relative_position\", \"speed\", \"edge_id\", \"lane_number\"]]\n",
    "\n",
    "        if MERGE:\n",
    "            df = df[(df.edge_id == 'inflow_highway')\n",
    "                    | (df.edge_id =='left')\n",
    "                    | (df.edge_id == 'center')\n",
    "                    | (df.edge_id == ':center_0')\n",
    "                    | (df.edge_id == ':center_1')]\n",
    "\n",
    "        # save the new dataframe under the path micro/{i}.csv\n",
    "        df.to_csv(os.path.join(directory_i, 'micro/{}.csv'.format(i)), index=False)\n",
    "\n",
    "        # delete the dataframe\n",
    "        del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the *edge_id* and *relative_position* data to generate global positions for each of the vehicles in the network, which we store under a new *global_position* attribute. The subsequent datapoints are removed, as they are no longer needed.\n",
    "\n",
    "We begin by defining an absolute position term for the starting position of each edge on the network. This is defined in the `edgestarts` variable by the cell below. We do this for the ring road and highway networks. Modify the capitalized variable at the start of the cell to match the network you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the network type\n",
    "RING    = True\n",
    "MERGE   = False\n",
    "HIGHWAY = False\n",
    "\n",
    "# length of the ring road\n",
    "RING_LENGTH = 1500\n",
    "\n",
    "# length of the highway\n",
    "MERGE_LENGTH = 1500\n",
    "\n",
    "# position on the on-ramp merge on the highway\n",
    "MERGE_POS = 1200\n",
    "\n",
    "\n",
    "if RING:\n",
    "    # length of inter-edge junctions\n",
    "    junction_length = 0.1\n",
    "\n",
    "    edgestarts = {\n",
    "        \"bottom\": 0,\n",
    "        \":right_0\": 0.25 * RING_LENGTH,\n",
    "        \"right\": 0.25 * RING_LENGTH + junction_length,\n",
    "        \":top_0\": 0.5 * RING_LENGTH + junction_length,\n",
    "        \"top\": 0.5 * RING_LENGTH + 2 * junction_length,\n",
    "        \":left_0\": 0.75 * RING_LENGTH + 2 * junction_length,\n",
    "        \"left\": 0.75 * RING_LENGTH + 3 * junction_length,\n",
    "        \":bottom_0\": RING_LENGTH + 3 * junction_length\n",
    "    }\n",
    "\n",
    "if MERGE:\n",
    "    # import network data from flow params\n",
    "    inflow_edge_len = 100\n",
    "    premerge = MERGE_POS - inflow_edge_len\n",
    "    postmerge = MERGE_LENGTH - MERGE_POS\n",
    "\n",
    "    # generate edge starts\n",
    "    edgestarts = {\n",
    "        'inflow_highway': 0,\n",
    "        'left': inflow_edge_len + 0.1,\n",
    "        'center': inflow_edge_len + premerge + 22.6,\n",
    "        'inflow_merge': inflow_edge_len + premerge + postmerge + 22.6,\n",
    "        'bottom': 2 * inflow_edge_len + premerge + postmerge + 22.7,\n",
    "        ':left_0': inflow_edge_len,\n",
    "        ':center_0': inflow_edge_len + premerge + 0.1,\n",
    "        ':center_1': inflow_edge_len + premerge + 0.1,\n",
    "        ':bottom_0': 2 * inflow_edge_len + premerge + postmerge + 22.6\n",
    "    }\n",
    "\n",
    "if HIGHWAY:\n",
    "    pass  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell then performs the operation of adding global positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "directory = [\"data/ring-1-lane/baseline/sumo-idm/50/micro\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/55/micro\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/60/micro\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/65/micro\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/70/micro\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/75/micro\"]\n",
    "\n",
    "\n",
    "for directory_i in directory:\n",
    "    # get the names of all files in the directory\n",
    "    files = os.listdir(directory_i)\n",
    "\n",
    "    for fp in files:\n",
    "        print(directory_i, fp)\n",
    "        # import the next file\n",
    "        df = pd.read_csv(os.path.join(directory_i, fp))\n",
    "\n",
    "        # create a column for the global positions\n",
    "        df[\"global_position\"] = 0\n",
    "\n",
    "        # add the global position of the start of the edge\n",
    "        for key in edgestarts.keys():\n",
    "            df.loc[df.edge_id == key, \"global_position\"] = edgestarts[key]\n",
    "\n",
    "        # add the relative position of the vehicles on the edge\n",
    "        df.global_position += df.relative_position\n",
    "\n",
    "        # remove the relative_position and edge_id columns\n",
    "        df = df[[\"time\", \"id\", \"global_position\", \"speed\", \"lane_number\"]]\n",
    "\n",
    "        # save the new dataframe under the path i.csv\n",
    "        df.to_csv(os.path.join(directory_i, fp), index=False)\n",
    "\n",
    "        # delete the dataframe\n",
    "        del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the below script generates meaningful macroscopic measurements from the available microscopic files. This is done by aggregates the densities and average speeds for sections of length `DX`. These aggregates can be collected for each lane separately by setting `INDIVIDUAL_LANES` to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# the discretization in space for the aggregation procedure\n",
    "DX = 50\n",
    "# the total length of the network (in meters)\n",
    "LENGTH = 1500\n",
    "# the discretization of time during the simulation procedure\n",
    "DT = 0.5\n",
    "# the total simulation time (in seconds)\n",
    "TOTAL_TIME = 3600\n",
    "# whether to compute the speeds and densities for each lane separately\n",
    "INDIVIDUAL_LANES = False\n",
    "\n",
    "\n",
    "# Specify the directories containing the files you'd like to compute \n",
    "# macroscopic properties for.\n",
    "directory = [\"data/ring-1-lane/baseline/sumo-idm/50\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/55\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/60\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/65\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/70\",\n",
    "             \"data/ring-1-lane/baseline/sumo-idm/75\"]\n",
    "\n",
    "\n",
    "for directory_i in directory:\n",
    "    directory_micro = os.path.join(directory_i, \"micro\")\n",
    "    directory_macro = os.path.join(directory_i, \"macro\")\n",
    "\n",
    "    # get the names of all files in the directory\n",
    "    files = os.listdir(directory_micro)\n",
    "    files = [fp for fp in files if fp.endswith(\".csv\")]\n",
    "\n",
    "    for i, fp in enumerate(sorted(files)):\n",
    "        # for timing purposes\n",
    "        print(directory_i, i)\n",
    "        t0 = time.time()\n",
    "\n",
    "        speeds = np.zeros((round(TOTAL_TIME/DT)+1, round(LENGTH/DX)))\n",
    "        num_vehicles = np.zeros((round(TOTAL_TIME/DT)+1, round(LENGTH/DX)))\n",
    "\n",
    "        with open(os.path.join(directory_micro, fp)) as csvfile:\n",
    "            # import the data\n",
    "            reader = csv.DictReader(csvfile)\n",
    "\n",
    "            # loop through each element\n",
    "            for row in reader:\n",
    "                indx_x = math.floor(float(row[\"time\"]) / DT)\n",
    "                indx_y = math.floor(float(row[\"global_position\"]) / DX)\n",
    "\n",
    "                try:\n",
    "                    speeds[indx_x, indx_y] += float(row[\"speed\"])\n",
    "                    num_vehicles[indx_x, indx_y] += 1\n",
    "                except IndexError:\n",
    "                    # Flow adds an extra step\n",
    "                    pass\n",
    "\n",
    "        # place the new data in an output dictionary\n",
    "        densities = num_vehicles / DX\n",
    "        speeds[num_vehicles==0] = 30  # set max speed for zero density sections\n",
    "        safe_num_vehicles = deepcopy(num_vehicles)\n",
    "        safe_num_vehicles[safe_num_vehicles==0] = 1\n",
    "        speeds = speeds / safe_num_vehicles.astype(float)\n",
    "        num_sections = speeds.shape[1]\n",
    "        output = {\"time\": np.arange(0, TOTAL_TIME+DT, DT)}\n",
    "        output.update({\"speed_{}\".format(j): list(speeds[:, j]) for j in range(num_sections)})\n",
    "        output.update({\"density_{}\".format(j): list(densities[:, j]) for j in range(num_sections)})\n",
    "\n",
    "        # store in a csv file\n",
    "        with open(os.path.join(directory_macro, \"{}.csv\".format(i)), \"w\") as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(output.keys())\n",
    "            writer.writerows(zip(*output.values()))\n",
    "\n",
    "        print(\" Done: {} sec\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial conditions from the above simulations can be extracted via the file below for later evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "LANES = 1\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "\n",
    "for n_vehicles in [50, 55, 60, 65, 70, 75]:\n",
    "    new_data = []\n",
    "    for i in range(50):\n",
    "        # modify this path to match the dataset\n",
    "        fp = \"data/ring-1-lane/baseline/sumo-idm/{}/macro/{}.csv\".format(LANES * n_vehicles, i)\n",
    "        df = pd.read_csv(fp)\n",
    "        df_i = df.iloc[WARMUP_STEPS, :]\n",
    "\n",
    "        new_data_point = {}\n",
    "        new_data_point.update({\"speed_{}\".format(i): df_i[\"speed_{}\".format(i)] for i in range(30)})\n",
    "        new_data_point.update({\"density_{}\".format(i): df_i[\"density_{}\".format(i)] for i in range(30)})\n",
    "        new_data.append(new_data_point)\n",
    "        \n",
    "        keys = new_data[0].keys()\n",
    "        with open('initial_conditions_{}.csv'.format(n_vehicles), 'w') as output_file:\n",
    "            dict_writer = csv.DictWriter(output_file, keys)\n",
    "            dict_writer.writeheader()\n",
    "            dict_writer.writerows(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plotting Microscopic Data\n",
    "\n",
    "We provide some supplementary methods for plotting time-space diagrams from the cleaned microscopic data. These plots are in many ways visually similar to the flow/density plots in the next section.\n",
    "\n",
    "The below method is heavily adopted from this [link](https://github.com/flow-project/flow/blob/master/flow/visualize/time_space_diagram.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "def time_space_diagram(df, \n",
    "                       lane=0, \n",
    "                       min_speed=0, \n",
    "                       max_speed=30, \n",
    "                       discontinuity=10,\n",
    "                       title=\"Time-Space Diagram\",\n",
    "                       save_path=None):\n",
    "    # leave only lane-relevant data\n",
    "    df = df[df.lane_number == lane]\n",
    "\n",
    "    # extract some variables from the dataset\n",
    "    times = sorted(list(np.unique(df.time)))\n",
    "    num_times = len(times)\n",
    "    vehicles = sorted(list(np.unique(df.id)))\n",
    "    num_vehicles = len(vehicles)\n",
    "\n",
    "    # empty arrays for the positions and speeds of all vehicles\n",
    "    pos = np.zeros((num_times, num_vehicles))\n",
    "    speed = np.zeros((num_times, num_vehicles))\n",
    "\n",
    "    # prepare the speed and absolute position in a way that is compatible with\n",
    "    # the space-time diagram, and compute the number of vehicles at each step\n",
    "    for j, veh_id in enumerate(vehicles):\n",
    "        df_j = df[df.id == veh_id]\n",
    "        pos_j = np.asarray(df_j.global_position)\n",
    "        speed_j = np.asarray(df_j.speed)\n",
    "        vehicle_times = np.asarray(df_j.time)\n",
    "        for k, vehicle_time in enumerate(vehicle_times):\n",
    "            index = times.index(vehicle_time)\n",
    "            pos[index, j] = pos_j[k]\n",
    "            speed[index, j] = speed_j[k]\n",
    "\n",
    "    # some plotting parameters\n",
    "    cdict = {\n",
    "        'red': ((0, 0, 0), (0.2, 1, 1), (0.6, 1, 1), (1, 0, 0)),\n",
    "        'green': ((0, 0, 0), (0.2, 0, 0), (0.6, 1, 1), (1, 1, 1)),\n",
    "        'blue': ((0, 0, 0), (0.2, 0, 0), (0.6, 0, 0), (1, 0, 0))\n",
    "    }\n",
    "    my_cmap = colors.LinearSegmentedColormap('my_colormap', cdict, 1024)\n",
    "\n",
    "    # perform plotting operation\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax = plt.axes()\n",
    "    norm = plt.Normalize(min_speed, max_speed)\n",
    "    cols = []\n",
    "\n",
    "    xmin = times[0]\n",
    "    xmax = times[-1]\n",
    "    xbuffer = (xmax - xmin) * 0.025  # 2.5% of range\n",
    "    ymin, ymax = np.amin(pos), np.amax(pos)\n",
    "    ybuffer = (ymax - ymin) * 0.025  # 2.5% of range\n",
    "\n",
    "    ax.set_xlim(xmin - xbuffer, xmax + xbuffer)\n",
    "    ax.set_ylim(ymin - ybuffer, ymax + ybuffer)\n",
    "\n",
    "    for indx_car in range(pos.shape[1]):\n",
    "        unique_car_pos = pos[:, indx_car]\n",
    "\n",
    "        # discontinuity from wraparound\n",
    "        disc = np.where(np.abs(np.diff(unique_car_pos)) >= discontinuity)[0] + 1\n",
    "        unique_car_time = np.insert(times, disc, np.nan)\n",
    "        unique_car_pos = np.insert(unique_car_pos, disc, np.nan)\n",
    "        unique_car_speed = np.insert(speed[:, indx_car], disc, np.nan)\n",
    "\n",
    "        points = np.array(\n",
    "            [unique_car_time, unique_car_pos]).T.reshape(-1, 1, 2)\n",
    "        segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "        lc = LineCollection(segments, cmap=my_cmap, norm=norm)\n",
    "\n",
    "        # Set the values used for color mapping\n",
    "        lc.set_array(unique_car_speed)\n",
    "        lc.set_linewidth(1.75)\n",
    "        cols.append(lc)\n",
    "\n",
    "    plt.title(title, fontsize=25)\n",
    "    plt.ylabel('Position (m)', fontsize=20)\n",
    "    plt.xlabel('Time (s)', fontsize=20)\n",
    "\n",
    "    for col in cols:\n",
    "        line = ax.add_collection(col)\n",
    "    cbar = plt.colorbar(line, ax=ax)\n",
    "    cbar.set_label('Velocity (m/s)', fontsize=20)\n",
    "    cbar.ax.tick_params(labelsize=18)\n",
    "\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Ring Road\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANES = 1\n",
    "\n",
    "for n_vehicles in [50, 55, 60, 65, 70, 75]:\n",
    "    for i in range(50):\n",
    "        # modify this path to match the dataset\n",
    "        fp = \"data/ring-1-lane/baseline/sumo-idm/{}/micro/{}.csv\".format(LANES * n_vehicles, i)\n",
    "        df = pd.read_csv(fp)\n",
    "\n",
    "        for lane in range(LANES):\n",
    "            time_space_diagram(\n",
    "                df,\n",
    "                lane,\n",
    "                min_speed=0,\n",
    "                max_speed=30,\n",
    "                title=\"\",\n",
    "                discontinuity=20,\n",
    "                save_path=os.path.join(fp.rsplit('/', 1)[0], \"ts-{}-{}.png\".format(i, lane))\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Merge\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANES = 1\n",
    "\n",
    "for inflow in [1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]:\n",
    "    for i in range(50):\n",
    "        # modify this path to match the dataset\n",
    "        fp = \"data/merge-1-lane/baseline/sumo-idm/{}/micro/{}.csv\".format(LANES * inflow, i)\n",
    "        df = pd.read_csv(fp)\n",
    "\n",
    "        for lane in range(LANES):\n",
    "            time_space_diagram(\n",
    "                df,\n",
    "                lane,\n",
    "                min_speed=0,\n",
    "                max_speed=30,\n",
    "                title=\"\",\n",
    "                discontinuity=20,\n",
    "                save_path=os.path.join(fp.rsplit('/', 1)[0], \"ts-{}-{}.png\".format(i, lane))\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Highway\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plotting Macroscopic Data\n",
    "\n",
    "We provide auxiliary methods for plotting the macroscopic traffic flow properties (i.e. flows and densities) from output files generating during the data cleaning procedure above. Examples of these plotting methods in action are available in the following subsections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def avg_speed_plot(dir_path, sub_paths):\n",
    "    # get the times from the first dataframe\n",
    "    df = pd.read_csv(os.path.join(dir_path, \"{}/micro/0.csv\".format(sub_paths[0])))\n",
    "    times = sorted(list(np.unique(df.time)))\n",
    "\n",
    "    # empty arrays for the average speeds of all vehicles\n",
    "    avg_speed = [[] for _ in range(len(sub_paths))]\n",
    "\n",
    "    for i, path in enumerate(sub_paths):\n",
    "        # extract the \".csv\" file names\n",
    "        filenames = os.listdir(os.path.join(dir_path, \"{}/micro\".format(path)))\n",
    "        filenames = [fp for fp in filenames if fp.endswith(\".csv\")]\n",
    "\n",
    "        for fp in filenames:\n",
    "            print(path, fp)\n",
    "            # get the dataframe\n",
    "            full_path = os.path.join(dir_path, \"{}/micro/{}\".format(path, fp))\n",
    "            df = pd.read_csv(full_path)\n",
    "\n",
    "            avg_speeds_i = []\n",
    "            for t in times:\n",
    "                df_t = df[df.time==t]\n",
    "                avg_speeds_i.append(np.mean(df_t.speed))\n",
    "\n",
    "            avg_speed[i].append(avg_speeds_i)\n",
    "\n",
    "        avg_speed[i] = np.array(avg_speed[i])        \n",
    "\n",
    "    labels = sub_paths\n",
    "    colors = plt.cm.get_cmap('tab10', len(labels)+1)\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    for i, (label, result) in enumerate(zip(labels, avg_speed)):\n",
    "        plt.plot(times, np.mean(result, 0),\n",
    "                 color=colors(i), linewidth=2, label=label)\n",
    "        plt.fill_between(times,\n",
    "                         np.mean(result, 0) - np.std(result, 0),\n",
    "                         np.mean(result, 0) + np.std(result, 0),\n",
    "                         alpha=0.25, color=colors(i))\n",
    "\n",
    "    plt.ylabel('Velocity (m/s)', fontsize=20)\n",
    "    plt.xlabel('Time (s)', fontsize=20)\n",
    "    plt.tick_params(labelsize=15)\n",
    "    plt.legend(fontsize=20)\n",
    "\n",
    "\n",
    "def flow_density_plot(df, \n",
    "                      total_time,\n",
    "                      length,\n",
    "                      min_speed=0,\n",
    "                      max_speed=30,\n",
    "                      min_density=0,\n",
    "                      max_density=0.2,\n",
    "                      speed_save_path=None,\n",
    "                      density_save_path=None,\n",
    "                      flow_save_path=None):\n",
    "    # some plotting parameters\n",
    "    cdict = {\n",
    "        'red': ((0, 0, 0), (0.2, 1, 1), (0.6, 1, 1), (1, 0, 0)),\n",
    "        'green': ((0, 0, 0), (0.2, 0, 0), (0.6, 1, 1), (1, 1, 1)),\n",
    "        'blue': ((0, 0, 0), (0.2, 0, 0), (0.6, 0, 0), (1, 0, 0))\n",
    "    }\n",
    "    my_cmap = colors.LinearSegmentedColormap('my_colormap', cdict, 1024)\n",
    "\n",
    "    speed_columns = [c for c in df.columns if c.startswith(\"speed\")]\n",
    "    a = np.asarray(df[speed_columns]).T\n",
    "\n",
    "    density_columns = [c for c in df.columns if c.startswith(\"density\")]\n",
    "    b = np.asarray(df[density_columns]).T\n",
    "\n",
    "    c = a * b * 3600\n",
    "\n",
    "    # Plot the average speed plots.\n",
    "    plt.figure(figsize=(16,9))\n",
    "    norm = plt.Normalize(min_speed, max_speed)\n",
    "    plt.xlabel(\"Time (s)\", fontsize=20)\n",
    "    plt.ylabel(\"Position (m)\", fontsize=20)\n",
    "    plt.imshow(a, extent=(0,total_time,0,length), origin='lower', aspect='auto', cmap=my_cmap, norm=norm)\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label('Velocity (m/s)', fontsize=20)\n",
    "    cbar.ax.tick_params(labelsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    if speed_save_path is not None:\n",
    "        plt.savefig(speed_save_path, bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot the density plots.\n",
    "    plt.figure(figsize=(16,9))\n",
    "    norm = plt.Normalize(min_density, max_density)\n",
    "    plt.xlabel(\"Time (s)\", fontsize=20)\n",
    "    plt.ylabel(\"Position (m)\", fontsize=20)\n",
    "    plt.imshow(b, extent=(0,total_time,0,length), origin='lower', aspect='auto', cmap=my_cmap, norm=norm)\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label('Density (veh/s)', fontsize=20)\n",
    "    cbar.ax.tick_params(labelsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    if density_save_path is not None:\n",
    "        plt.savefig(density_save_path, bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "    # Plot the flow plots.\n",
    "    plt.figure(figsize=(16,9))\n",
    "    norm = plt.Normalize(min_speed * min_density * 3600, 0.2 * max_speed * max_density * 3600)\n",
    "    plt.xlabel(\"Time (s)\", fontsize=20)\n",
    "    plt.ylabel(\"Position (m)\", fontsize=20)\n",
    "    plt.imshow(c, extent=(0,total_time,0,length), origin='lower', aspect='auto', cmap=my_cmap, norm=norm)\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label('flow (veh/hr)', fontsize=20)\n",
    "    cbar.ax.tick_params(labelsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    if flow_save_path is not None:\n",
    "        plt.savefig(flow_save_path, bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Ring Road\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# modify this path to match the dataset\n",
    "DIR_PATH = \"data/ring-1-lane/baseline/sumo-idm\"\n",
    "SUB_PATHS = [\"50\", \"55\", \"60\", \"65\", \"70\", \"75\"]\n",
    "\n",
    "a = avg_speed_plot(DIR_PATH, SUB_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANES = 1\n",
    "\n",
    "for n_vehicles in [50, 55, 60, 65, 70, 75]:\n",
    "    for i in range(50):\n",
    "        # modify this path to match the dataset\n",
    "        fp = \"data/ring-1-lane/baseline/sumo-idm/{}/macro/{}.csv\".format(LANES * n_vehicles, i)\n",
    "        df = pd.read_csv(fp)\n",
    "\n",
    "        flow_density_plot(\n",
    "            df, \n",
    "            total_time=3600,\n",
    "            length=1500,\n",
    "            speed_save_path=os.path.join(fp.rsplit('/', 1)[0], \"speed-{}.png\".format(i)),\n",
    "            density_save_path=os.path.join(fp.rsplit('/', 1)[0], \"density-{}.png\".format(i)),\n",
    "            flow_save_path=os.path.join(fp.rsplit('/', 1)[0], \"flow-{}.png\".format(i))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Merge\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Highway\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time-Frequency Analysis of Macroscopic Data\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Ring Road\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Highway\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modeling Results\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Lighthill-Whitham-Richards (LWR) Model\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Aw-Rascle-Zhang (ARZ) Model\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Linearized ARZ Model\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Non-Local Model\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Fully-Connected Neural Network\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
